{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import hashlib\n",
    "import json\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(parent_dir)\n",
    "from postgres import Postgres\n",
    "\n",
    "pg = Postgres()\n",
    "\n",
    "def create_table_if_not_exists():\n",
    "    pg.insert(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS text_chunks (\n",
    "        chunk_id VARCHAR NOT NULL,  -- Must be VARCHAR to match the referenced type\n",
    "        document_id TEXT NOT NULL,\n",
    "        document_geo_boundary GEOMETRY,\n",
    "        geo_scope TEXT,\n",
    "        chunk_sections TEXT,\n",
    "        chunk_text TEXT,\n",
    "        chunk_geom GEOMETRY,\n",
    "        distance_from_document_geom DOUBLE PRECISION,\n",
    "        openai_topic_labels JSONB,\n",
    "        openai_geo_labels JSONB,\n",
    "        experiment TEXT,\n",
    "        lpa TEXT,\n",
    "        council_type TEXT,\n",
    "        neighbourhood TEXT,\n",
    "        document_title TEXT,\n",
    "        document_category TEXT,\n",
    "        document_start_year INT,\n",
    "        document_end_year INT,\n",
    "        chunkking_details JSONB,\n",
    "        chunk_vector VECTOR(1536),\n",
    "        \n",
    "        -- Define `chunk_id` as a foreign key referencing `langchain_pg_embedding(id)`\n",
    "        CONSTRAINT fk_chunk_id\n",
    "            FOREIGN KEY (chunk_id) REFERENCES langchain_pg_embedding(id)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "def add_data():\n",
    "    # Step 2: Query the data from `langchain_pg_embedding`\n",
    "    print('cycle')\n",
    "    fetch_unprocessed_rows_query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM langchain_pg_embedding AS l\n",
    "        WHERE NOT EXISTS (\n",
    "            SELECT 1 \n",
    "            FROM text_chunks AS t\n",
    "            WHERE t.chunk_id = l.id\n",
    "        )\n",
    "        AND cmetadata->>'chunker' = 'sherpa'\n",
    "        LIMIT 20;\n",
    "    \"\"\" \n",
    "    rows = pg.query(fetch_unprocessed_rows_query)\n",
    "\n",
    "    # Step 3: Process each row and insert into `text_chunks`\n",
    "    for row in rows:\n",
    "        row = dict(row)\n",
    "        # Access fields directly by column name due to RealDictCursor\n",
    "        cmetadata = row['cmetadata']\n",
    "\n",
    "        # Build the transformed data with Python, handling missing fields with `.get()`\n",
    "        document_id = hashlib.md5(\n",
    "            (cmetadata.get('document_title', '') +\n",
    "            str(cmetadata.get('start_year', '')) +\n",
    "            str(cmetadata.get('end_year', '')) +\n",
    "            cmetadata.get('lpa', '')).encode('utf-8')\n",
    "        ).hexdigest()\n",
    "        \n",
    "        data = {\n",
    "            \"chunk_id\": row['id'],\n",
    "            \"document_id\": document_id,\n",
    "            \"document_geo_boundary\": None,\n",
    "            \"geo_scope\": \"\",\n",
    "            \"chunk_sections\": cmetadata.get('sections', ''),\n",
    "            \"chunk_text\": cmetadata.get('text', ''),\n",
    "            \"distance_from_document_geom\": None,\n",
    "            \"openai_topic_labels\": json.dumps(cmetadata.get('openai_labels', {})),  \n",
    "            \"openai_geo_labels\": json.dumps(cmetadata.get('openai_geo_labels', {})),\n",
    "            \"experiment\": cmetadata.get('experiment', ''),\n",
    "            \"lpa\": cmetadata.get('lpa', ''),\n",
    "            \"council_type\": cmetadata.get('council type', ''),\n",
    "            \"neighbourhood\": cmetadata.get('neighbourhood', ''),\n",
    "            \"document_title\": cmetadata.get('document_title', ''),\n",
    "            \"document_category\": cmetadata.get('category', ''),\n",
    "            \"document_start_year\": int(cmetadata.get('start_year', 0)),\n",
    "            \"document_end_year\": int(cmetadata.get('end_year', 0)),\n",
    "            \"chunkking_details\": json.dumps({\n",
    "                \"chunker\": cmetadata.get('chunker', ''),\n",
    "                \"file\": cmetadata.get('file', ''),\n",
    "                \"url\": cmetadata.get('url', ''),\n",
    "                \"page\": int(cmetadata.get('page', 0)),\n",
    "                \"block_idx\": int(cmetadata.get('block_idx', 0)),\n",
    "                \"level\": int(cmetadata.get('level', 0)),\n",
    "                \"coalesced_with\": cmetadata.get('coalesced_with', ''),\n",
    "                \"notes\": cmetadata.get('notes', '')\n",
    "            }),\n",
    "            \"chunk_vector\": row['embedding']  # Adjusted to use column name 'vector'\n",
    "        }\n",
    "\n",
    "        # Insert into `text_chunks`\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO text_chunks (\n",
    "                chunk_id,\n",
    "                document_id, document_geo_boundary, geo_scope, chunk_sections, chunk_text,\n",
    "                chunk_geom, distance_from_document_geom, openai_topic_labels, openai_geo_labels,\n",
    "                experiment, lpa, council_type, neighbourhood, document_title, document_category,\n",
    "                document_start_year, document_end_year, chunkking_details, chunk_vector\n",
    "            ) VALUES (\n",
    "                %(chunk_id)s,\n",
    "                %(document_id)s, %(document_geo_boundary)s, %(geo_scope)s, %(chunk_sections)s,\n",
    "                %(chunk_text)s, %(chunk_geom)s, %(distance_from_document_geom)s,\n",
    "                %(openai_topic_labels)s, %(openai_geo_labels)s, %(experiment)s, %(lpa)s,\n",
    "                %(council_type)s, %(neighbourhood)s, %(document_title)s, %(document_category)s,\n",
    "                %(document_start_year)s, %(document_end_year)s, %(chunkking_details)s, %(chunk_vector)s\n",
    "            );\n",
    "        \"\"\"\n",
    "        pg.insert(insert_query, data)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    add_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

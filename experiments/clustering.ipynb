{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(2800, 1536)\n"
     ]
    }
   ],
   "source": [
    "from postgres import Postgres\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pg = Postgres()\n",
    "\n",
    "results = pg.query(\n",
    "    \"\"\"\n",
    " SELECT \n",
    "\tcmetadata->'text' as text,\n",
    "\tembedding\n",
    "    FROM langchain_pg_embedding \n",
    "\tWHERE cmetadata @> '{\"chunker\": \"sherpa\"}' \n",
    "    AND LENGTH(cmetadata->>'text'::TEXT) > 40\n",
    "\tLIMIT 5000;\n",
    "                   \n",
    "\t\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"text\", \"embedding\"])\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(ast.literal_eval)\n",
    "print(type(df[\"embedding\"][0]))\n",
    "embeddings_array = np.array(df[\"embedding\"].tolist())\n",
    "print(embeddings_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>[-0.01311813099129231, -0.03373433119564931, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National and Local Planning Context</td>\n",
       "      <td>[-0.0017892545784752606, -0.028909997633742576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Parish of West Wittering</td>\n",
       "      <td>[-0.003959975990752514, -0.014515406848524297,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vision &amp; Objectives</td>\n",
       "      <td>[-0.007655357440304239, -0.02439560581313669, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Policies &amp; Proposals</td>\n",
       "      <td>[0.01715402574925511, -0.03274377222368811, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text  \\\n",
       "0                         Introduction   \n",
       "1  National and Local Planning Context   \n",
       "2         The Parish of West Wittering   \n",
       "3                  Vision & Objectives   \n",
       "4                 Policies & Proposals   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.01311813099129231, -0.03373433119564931, 0...  \n",
       "1  [-0.0017892545784752606, -0.028909997633742576...  \n",
       "2  [-0.003959975990752514, -0.014515406848524297,...  \n",
       "3  [-0.007655357440304239, -0.02439560581313669, ...  \n",
       "4  [0.01715402574925511, -0.03274377222368811, 0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m embeddings_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m----> 3\u001b[0m reduced_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Standardize the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m~/Projects/neighbourhood-plans-server/venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/Projects/neighbourhood-plans-server/venv/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/neighbourhood-plans-server/venv/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:1176\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1176\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/Projects/neighbourhood-plans-server/venv/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:918\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    912\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE with method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not accept sparse \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed distance matrix. Use method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor provide the dense distance matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m         )\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_components\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be inferior to 4 for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut algorithm as it relies on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquad-tree or oct-tree.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m     )\n\u001b[1;32m    923\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    925\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree."
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=50, random_state=42)\n",
    "embeddings_array = np.array(df[\"embedding\"].tolist())\n",
    "reduced_embeddings = tsne.fit_transform(embeddings_array)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "reduced_embeddings = scaler.fit_transform(reduced_embeddings)\n",
    "\n",
    "df[\"reduced_embedding\"] = list(reduced_embeddings)\n",
    "\n",
    "\n",
    "# Clustering\n",
    "dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value)\n",
    "clusters = dbscan.fit_predict(reduced_embeddings)\n",
    "df[\"cluster\"] = clusters\n",
    "\n",
    "# Print the number of clusters found\n",
    "num_unique_clusters = len(set(clusters))\n",
    "print(f\"Number of clusters found: {num_unique_clusters}\")\n",
    "\n",
    "df[\"tokens\"] = df[\"text\"]\n",
    "\n",
    "# Compute word frequencies for each cluster\n",
    "for cluster in range(1000):\n",
    "    cluster_df = df[df[\"cluster\"] == cluster]\n",
    "    if not cluster_df.empty:\n",
    "        cluster_tokens = df[df[\"cluster\"] == cluster][\"tokens\"].explode()\n",
    "        word_freq = Counter(cluster_tokens)\n",
    "        most_common_words = word_freq.most_common(10)  # Top 10 words\n",
    "        print(f\"Cluster {cluster} Top Words:\")\n",
    "        for word, freq in most_common_words:\n",
    "            print(f\"{word}: {freq}\")\n",
    "\n",
    "        sample_docs = (\n",
    "            df[df[\"cluster\"] == cluster][\"text\"].sample(5, replace=True).tolist()\n",
    "        )\n",
    "        for doc in sample_docs:\n",
    "            print(f\"- {doc}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
